{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5f46af",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b67259e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "# libraries feng and evaluation\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Other libraries\n",
    "import optuna\n",
    "import json\n",
    "import src.util as utils\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0677b3",
   "metadata": {},
   "source": [
    "# Load Config and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecfc56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c682571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_feng(params: dict) -> pd.DataFrame:\n",
    "    # Load train set\n",
    "    X_train = utils.pickle_load(params['train_processed_set_path'][0])\n",
    "    y_train = utils.pickle_load(params['train_processed_set_path'][1])\n",
    "    \n",
    "    # Load train set transforming with log\n",
    "    X_train_log = utils.pickle_load(params['train_processed_log_set_path'][0])\n",
    "    y_train_log = utils.pickle_load(params['train_processed_log_set_path'][1])\n",
    "    \n",
    "    # Load train set SMOTE\n",
    "    X_train_SMOTE = utils.pickle_load(params['train_processed_SMOTE_set_path'][0])\n",
    "    y_train_SMOTE = utils.pickle_load(params['train_processed_SMOTE_set_path'][1])\n",
    "    \n",
    "    # Load train set wiht log and SMOTE\n",
    "    X_train_log_SMOTE = utils.pickle_load(params['train_processed_log_SMOTE_set_path'][0])\n",
    "    y_train_log_SMOTE = utils.pickle_load(params['train_processed_log_SMOTE_set_path'][1])\n",
    "\n",
    "    return X_train, y_train, X_train_log, y_train_log, X_train_SMOTE, y_train_SMOTE, X_train_log_SMOTE, y_train_log_SMOTE\n",
    "\n",
    "def load_valid(params: dict) -> pd.DataFrame:\n",
    "    # Load valid set\n",
    "    X_valid = utils.pickle_load(params['valid_processed_set_path'][0])\n",
    "    y_valid = utils.pickle_load(params['valid_processed_set_path'][1])\n",
    "    \n",
    "    # Load valid set with transforming log\n",
    "    X_valid_log = utils.pickle_load(params['valid_processed_log_set_path'][0])\n",
    "    y_valid_log = utils.pickle_load(params['valid_processed_log_set_path'][1])\n",
    "\n",
    "    return X_valid, y_valid, X_valid_log, y_valid_log\n",
    "\n",
    "def load_test(params: dict) -> pd.DataFrame:\n",
    "    # Load test set\n",
    "    X_test = utils.pickle_load(params['test_processed_set_path'][0])\n",
    "    y_test = utils.pickle_load(params['test_processed_set_path'][1])\n",
    "    \n",
    "    # Load test set with transforming log\n",
    "    X_test_log = utils.pickle_load(params['test_processed_log_set_path'][0])\n",
    "    y_test_log = utils.pickle_load(params['test_processed_log_set_path'][1])\n",
    "\n",
    "    return X_test, y_test, X_test_log, y_test_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53d70d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data train\n",
    "X_train, y_train, X_train_log, y_train_log, X_train_SMOTE, y_train_SMOTE, X_train_log_SMOTE, y_train_log_SMOTE = load_train_feng(config)\n",
    "\n",
    "# laod data valid\n",
    "X_valid, y_valid, X_valid_log, y_valid_log = load_valid(config)\n",
    "\n",
    "# Load data test\n",
    "X_test, y_test, X_test_log, y_test_log = load_test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362862ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Set Train---------------\n",
      "((700, 7), (700,)) \n",
      "\n",
      "((700, 7), (700,)) \n",
      "\n",
      "((1330, 7), (1330,)) \n",
      "\n",
      "((1330, 7), (1330,)) \n",
      "\n",
      "------------Set Valid---------------\n",
      "((150, 7), (150,)) \n",
      "\n",
      "((150, 7), (150,)) \n",
      "\n",
      "------------Set Test---------------\n",
      "((150, 7), (150,)) \n",
      "\n",
      "((150, 7), (150,)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checpoint/sanity check\n",
    "print('------------Set Train---------------')\n",
    "print((X_train.shape, y_train.shape), '\\n')\n",
    "print((X_train_log.shape, y_train_log.shape), '\\n')\n",
    "print((X_train_SMOTE.shape, y_train_SMOTE.shape), '\\n')\n",
    "print((X_train_log_SMOTE.shape, y_train_log_SMOTE.shape), '\\n')\n",
    "\n",
    "print('------------Set Valid---------------')\n",
    "print((X_valid.shape, y_valid.shape), '\\n')\n",
    "print((X_valid_log.shape, y_valid_log.shape), '\\n')\n",
    "\n",
    "print('------------Set Test---------------')\n",
    "print((X_test.shape, y_test.shape), '\\n')\n",
    "print((X_test_log.shape, y_test_log.shape), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d73d70",
   "metadata": {},
   "source": [
    "For the context, the transformation log only in features (X variables). So, the naming of the log in target/label is for the sake of differentiation, the value doesn't change. Here's the proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc10bab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    665\n",
       "1     35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c3c02c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    665\n",
       "1     35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f89ed329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    665\n",
       "1    665\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log_SMOTE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3917910a",
   "metadata": {},
   "source": [
    "# Compare Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e60725ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize model\n",
    "models = {\n",
    "    'gbc': GradientBoostingClassifier(random_state=42),\n",
    "    'lightgbm': lgb.LGBMClassifier(random_state=42, verbose=-1),\n",
    "    'xgb': xgb.XGBClassifier(random_state=42), \n",
    "    'rf': RandomForestClassifier(random_state=42),\n",
    "    'et': ExtraTreesClassifier(random_state=42),\n",
    "    'dt': DecisionTreeClassifier(random_state=42),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'ada': AdaBoostClassifier(random_state=42),\n",
    "    'lr': LogisticRegression(random_state=42, solver='liblinear'), \n",
    "    'svm': SVC(random_state=42, probability=True),\n",
    "}\n",
    "\n",
    "# create function\n",
    "def get_best_models_cv(X: pd.DataFrame, y: pd.Series, models: dict, sort_by: str, n_splits: int = 5):\n",
    "    \"\"\"\n",
    "    Performs cross-validation for each model and returns a DataFrame of the results.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): The training features DataFrame.\n",
    "        y (pd.Series): The training target Series.\n",
    "        models (dict): A dictionary containing model names and model objects.\n",
    "        sort_by (str): The metric to sort the results by.\n",
    "        n_splits (int): The number of splits for StratifiedKFold.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the average metrics for each model, sorted.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    results = pd.DataFrame(columns=['Model', 'Accuracy', 'AUC', 'Recall', 'Prec.', 'F1'])\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        accuracy_scores = []\n",
    "        auc_scores = []\n",
    "        recall_scores = []\n",
    "        precision_scores = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for train_index, val_index in skf.split(X, y):\n",
    "            X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = model.predict(X_val_fold)\n",
    "            \n",
    "            # to handle cases where the model fails predict_proba\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                try: \n",
    "                    y_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "                    auc_scores.append(roc_auc_score(y_val_fold, y_proba))\n",
    "                except (ValueError, AttributeError):\n",
    "                    auc_scores.append(0.0) \n",
    "            else:\n",
    "                auc_scores.append(0.0)\n",
    "\n",
    "            accuracy_scores.append(accuracy_score(y_val_fold, y_pred))\n",
    "            recall_scores.append(recall_score(y_val_fold, y_pred))\n",
    "            precision_scores.append(precision_score(y_val_fold, y_pred))\n",
    "            f1_scores.append(f1_score(y_val_fold, y_pred))\n",
    "        \n",
    "        results.loc[len(results)] = [\n",
    "            name,\n",
    "            pd.Series(accuracy_scores).mean(),\n",
    "            pd.Series(auc_scores).mean(),\n",
    "            pd.Series(recall_scores).mean(),\n",
    "            pd.Series(precision_scores).mean(),\n",
    "            pd.Series(f1_scores).mean()\n",
    "        ]\n",
    "        \n",
    "    return results.sort_values(by=sort_by, ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d8a0a",
   "metadata": {},
   "source": [
    "## Data No Transforming\n",
    "\n",
    "1. The data named into X_train and y_train\n",
    "2. No Transfomring means the `amount` features is left to follow the original data\n",
    "3. The unbalanced label is not handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83e57255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# try experiment with data Not Transforming\n",
    "experiment_in_data_not_transforming = get_best_models_cv(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    models,\n",
    "    sort_by='F1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51414f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.908571</td>\n",
       "      <td>0.532331</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>et</td>\n",
       "      <td>0.901429</td>\n",
       "      <td>0.504619</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.048571</td>\n",
       "      <td>0.052101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.917143</td>\n",
       "      <td>0.478733</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.932857</td>\n",
       "      <td>0.539527</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>0.602578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gbc</td>\n",
       "      <td>0.938571</td>\n",
       "      <td>0.574651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.537164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.526960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.479699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.435016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy       AUC    Recall     Prec.        F1\n",
       "0        dt  0.908571  0.532331  0.114286  0.097222  0.105000\n",
       "1        et  0.901429  0.504619  0.057143  0.048571  0.052101\n",
       "2        rf  0.917143  0.478733  0.028571  0.050000  0.036364\n",
       "3       xgb  0.932857  0.539527  0.028571  0.028571  0.028571\n",
       "4  lightgbm  0.925714  0.602578  0.000000  0.000000  0.000000\n",
       "5       gbc  0.938571  0.574651  0.000000  0.000000  0.000000\n",
       "6       knn  0.950000  0.537164  0.000000  0.000000  0.000000\n",
       "7       ada  0.950000  0.526960  0.000000  0.000000  0.000000\n",
       "8        lr  0.950000  0.479699  0.000000  0.000000  0.000000\n",
       "9       svm  0.950000  0.435016  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_in_data_not_transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4b1f7",
   "metadata": {},
   "source": [
    "## Data SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e927a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try experiment with data Not Transforming\n",
    "experiment_in_data_smote = get_best_models_cv(\n",
    "    X_train_SMOTE, \n",
    "    y_train_SMOTE,\n",
    "    models,\n",
    "    sort_by='Accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f798624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbc</td>\n",
       "      <td>0.939098</td>\n",
       "      <td>0.976635</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.967452</td>\n",
       "      <td>0.937254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.936090</td>\n",
       "      <td>0.979637</td>\n",
       "      <td>0.927820</td>\n",
       "      <td>0.944148</td>\n",
       "      <td>0.935592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.935338</td>\n",
       "      <td>0.977059</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.945885</td>\n",
       "      <td>0.934827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.927068</td>\n",
       "      <td>0.977918</td>\n",
       "      <td>0.921805</td>\n",
       "      <td>0.932259</td>\n",
       "      <td>0.926731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>et</td>\n",
       "      <td>0.927068</td>\n",
       "      <td>0.962112</td>\n",
       "      <td>0.921805</td>\n",
       "      <td>0.932467</td>\n",
       "      <td>0.926761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.912782</td>\n",
       "      <td>0.912782</td>\n",
       "      <td>0.912782</td>\n",
       "      <td>0.913442</td>\n",
       "      <td>0.912757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.893233</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.885573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.727068</td>\n",
       "      <td>0.814342</td>\n",
       "      <td>0.881203</td>\n",
       "      <td>0.673666</td>\n",
       "      <td>0.763496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.567669</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.560404</td>\n",
       "      <td>0.593234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.556391</td>\n",
       "      <td>0.578439</td>\n",
       "      <td>0.639098</td>\n",
       "      <td>0.550693</td>\n",
       "      <td>0.581447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy       AUC    Recall     Prec.        F1\n",
       "0       gbc  0.939098  0.976635  0.909774  0.967452  0.937254\n",
       "1       xgb  0.936090  0.979637  0.927820  0.944148  0.935592\n",
       "2  lightgbm  0.935338  0.977059  0.924812  0.945885  0.934827\n",
       "3        rf  0.927068  0.977918  0.921805  0.932259  0.926731\n",
       "4        et  0.927068  0.962112  0.921805  0.932467  0.926761\n",
       "5        dt  0.912782  0.912782  0.912782  0.913442  0.912757\n",
       "6       ada  0.893233  0.953372  0.821053  0.966667  0.885573\n",
       "7       knn  0.727068  0.814342  0.881203  0.673666  0.763496\n",
       "8        lr  0.567669  0.583538  0.631579  0.560404  0.593234\n",
       "9       svm  0.556391  0.578439  0.639098  0.550693  0.581447"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_in_data_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577e50e",
   "metadata": {},
   "source": [
    "## Data Transforming Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c3e819d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.518045</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.082143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>et</td>\n",
       "      <td>0.898571</td>\n",
       "      <td>0.501396</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.050794</td>\n",
       "      <td>0.053571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.496885</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.932857</td>\n",
       "      <td>0.539527</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>0.602578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gbc</td>\n",
       "      <td>0.938571</td>\n",
       "      <td>0.574221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.472718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.526960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.491085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.512997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy       AUC    Recall     Prec.        F1\n",
       "0        dt  0.907143  0.518045  0.085714  0.079365  0.082143\n",
       "1        et  0.898571  0.501396  0.057143  0.050794  0.053571\n",
       "2        rf  0.910000  0.496885  0.028571  0.040000  0.033333\n",
       "3       xgb  0.932857  0.539527  0.028571  0.028571  0.028571\n",
       "4  lightgbm  0.925714  0.602578  0.000000  0.000000  0.000000\n",
       "5       gbc  0.938571  0.574221  0.000000  0.000000  0.000000\n",
       "6       knn  0.950000  0.472718  0.000000  0.000000  0.000000\n",
       "7       ada  0.950000  0.526960  0.000000  0.000000  0.000000\n",
       "8        lr  0.950000  0.491085  0.000000  0.000000  0.000000\n",
       "9       svm  0.950000  0.512997  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_in_data_transforming = get_best_models_cv(\n",
    "    X_train_log,\n",
    "    y_train_log,\n",
    "    models,\n",
    "    sort_by='F1'\n",
    ")\n",
    "\n",
    "experiment_in_data_transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e93d6c",
   "metadata": {},
   "source": [
    "## Data Trasnforming log and SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea502738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.952383</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.864988</td>\n",
       "      <td>0.875193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.872180</td>\n",
       "      <td>0.953474</td>\n",
       "      <td>0.867669</td>\n",
       "      <td>0.875613</td>\n",
       "      <td>0.871611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gbc</td>\n",
       "      <td>0.870677</td>\n",
       "      <td>0.953214</td>\n",
       "      <td>0.872180</td>\n",
       "      <td>0.869660</td>\n",
       "      <td>0.870688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.942716</td>\n",
       "      <td>0.869173</td>\n",
       "      <td>0.858691</td>\n",
       "      <td>0.863812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>et</td>\n",
       "      <td>0.861654</td>\n",
       "      <td>0.896314</td>\n",
       "      <td>0.866165</td>\n",
       "      <td>0.858274</td>\n",
       "      <td>0.862113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.847368</td>\n",
       "      <td>0.847368</td>\n",
       "      <td>0.855639</td>\n",
       "      <td>0.841654</td>\n",
       "      <td>0.848503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.839850</td>\n",
       "      <td>0.917542</td>\n",
       "      <td>0.897744</td>\n",
       "      <td>0.805072</td>\n",
       "      <td>0.848635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.743609</td>\n",
       "      <td>0.827780</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.709621</td>\n",
       "      <td>0.764001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.655639</td>\n",
       "      <td>0.737928</td>\n",
       "      <td>0.806015</td>\n",
       "      <td>0.619621</td>\n",
       "      <td>0.700544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.591729</td>\n",
       "      <td>0.605619</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.570968</td>\n",
       "      <td>0.645530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy       AUC    Recall     Prec.        F1\n",
       "0  lightgbm  0.873684  0.952383  0.885714  0.864988  0.875193\n",
       "1       xgb  0.872180  0.953474  0.867669  0.875613  0.871611\n",
       "2       gbc  0.870677  0.953214  0.872180  0.869660  0.870688\n",
       "3        rf  0.863158  0.942716  0.869173  0.858691  0.863812\n",
       "4        et  0.861654  0.896314  0.866165  0.858274  0.862113\n",
       "5        dt  0.847368  0.847368  0.855639  0.841654  0.848503\n",
       "6       knn  0.839850  0.917542  0.897744  0.805072  0.848635\n",
       "7       ada  0.743609  0.827780  0.831579  0.709621  0.764001\n",
       "8       svm  0.655639  0.737928  0.806015  0.619621  0.700544\n",
       "9        lr  0.591729  0.605619  0.742857  0.570968  0.645530"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_in_data_transforming_smote = get_best_models_cv(\n",
    "    X_train_log_SMOTE,\n",
    "    y_train_log_SMOTE,\n",
    "    models,\n",
    "    sort_by='Accuracy'\n",
    ")\n",
    "\n",
    "experiment_in_data_transforming_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd1971",
   "metadata": {},
   "source": [
    "## Comparing The Result\n",
    "\n",
    "1. For the experiment on the data without log transformation, the accuracy metrics appear to be good. However, accuracy is not a suitable metric for imbalanced data. A more appropriate metric, such as the F1-Score, shows very low values, only around 10%.\n",
    "\n",
    "2. The same pattern is observed with the data where the amount feature was log-transformed. The accuracy is still high, but once again, the F1-score remains very poor. In fact, the F1-score after the log transformation is even worse compared to the data without the log transformation.\n",
    "\n",
    "3. **In the SMOTE data experiment, the scores across all metrics seem good. However, it is important to note that these high scores are likely due to overfitting, as the evaluation was based on synthetic data created by the SMOTE algorithm.**\n",
    "\n",
    "4. Regarding the SMOTE data, with or without log transformation, the performance is consistently better with the non-transformed data. The SMOTE-only data shows a slightly better performance compared to the SMOTE with log transformation data.\n",
    "\n",
    "5. Therefore, further validation and evaluation will be conducted to test the model's performance on non-synthetic data (the original data that the model has not seen) to get a realistic assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa0b16",
   "metadata": {},
   "source": [
    "# Validation of The Result\n",
    "\n",
    "Notes:\n",
    "* The original data has only 3 features and 1 label. These three features are very general, describing only the merchant type, device type, and the total amount spent.\n",
    "* Due to the limited data quality, the models may not be able to learn meaningful patterns effectively.\n",
    "* It is highly probable that predictions are based on chance or a lack of data context. This increases the likelihood of the models overfitting and performing poorly on the validation and test sets.\n",
    "* **The models we chose to use are based on the best performance, ranging from complex models like Gradient Boosting to a simpler model like Decision Tree.**\n",
    "* Tree-based models are favored over linear or distance-based models due to their better empirical performance. This, however, does not change our belief that there is still a significant potential for overfitting because of the data's limited quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a49a7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model (initliaze)\n",
    "gbc_model = GradientBoostingClassifier(random_state=42)\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "dt_model = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "719ace2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model_cv_report(model, X_train, y_train, n_splits=5):\n",
    "    \"\"\"\n",
    "    Performs cross-validation on a single model and returns a DataFrame\n",
    "    containing per-fold metrics and their average.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    results = pd.DataFrame(columns=['Fold', 'Accuracy', 'AUC', 'Recall', 'Prec.', 'F1'])\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    auc_scores = []\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        # Fit the model on each fold\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predict on the validation fold\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        # Handle models without predict_proba if necessary, though it's assumed for AUC\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            try: \n",
    "                y_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "                auc = roc_auc_score(y_val_fold, y_proba)\n",
    "            except (ValueError, AttributeError):\n",
    "                auc = 0.0\n",
    "        else:\n",
    "            auc = 0.0\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = accuracy_score(y_val_fold, y_pred)\n",
    "        rec = recall_score(y_val_fold, y_pred, zero_division=0)\n",
    "        prec = precision_score(y_val_fold, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
    "\n",
    "        # Store metrics for calculating the average\n",
    "        accuracy_scores.append(acc)\n",
    "        auc_scores.append(auc)\n",
    "        recall_scores.append(rec)\n",
    "        precision_scores.append(prec)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        # Store per-fold results\n",
    "        results.loc[len(results)] = [f\"Fold {fold}\", acc, auc, rec, prec, f1]\n",
    "\n",
    "    # Add the mean row\n",
    "    results.loc[len(results)] = ['Mean', pd.Series(accuracy_scores).mean(), pd.Series(auc_scores).mean(), pd.Series(recall_scores).mean(), pd.Series(precision_scores).mean(), pd.Series(f1_scores).mean()]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2a209",
   "metadata": {},
   "source": [
    "## model gbc and xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e30479e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fold 0</td>\n",
       "      <td>0.936090</td>\n",
       "      <td>0.975748</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fold 1</td>\n",
       "      <td>0.954887</td>\n",
       "      <td>0.992114</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.961832</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fold 2</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.965487</td>\n",
       "      <td>0.887218</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.929134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fold 3</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.983832</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fold 4</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.965996</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.924812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.939098</td>\n",
       "      <td>0.976635</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.967452</td>\n",
       "      <td>0.937254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fold  Accuracy       AUC    Recall     Prec.        F1\n",
       "0  Fold 0  0.936090  0.975748  0.894737  0.975410  0.933333\n",
       "1  Fold 1  0.954887  0.992114  0.947368  0.961832  0.954545\n",
       "2  Fold 2  0.932331  0.965487  0.887218  0.975207  0.929134\n",
       "3  Fold 3  0.947368  0.983832  0.894737  1.000000  0.944444\n",
       "4  Fold 4  0.924812  0.965996  0.924812  0.924812  0.924812\n",
       "5    Mean  0.939098  0.976635  0.909774  0.967452  0.937254"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to fitting in mutlitple fold\n",
    "single_model_cv_report(gbc_model, X_train_SMOTE, y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f00a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_metrics_df(model_name, y_true, y_pred, y_proba):\n",
    "    \"\"\"\n",
    "     Calculates the evaluation metrics and returns them as a DataFrame.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': [model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Recall': [recall],\n",
    "        'Prec.': [precision],\n",
    "        'F1': [f1],\n",
    "        'AUC': [auc]\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d945d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gradient boosting classifier</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Accuracy  Recall  Prec.   F1       AUC\n",
       "0  gradient boosting classifier  0.913333     0.0    0.0  0.0  0.371039"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the result on data that the model has never seen before\n",
    "# predict on set validation (X_valid)\n",
    "fit_model_gbc = gbc_model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "y_pred_gbc = fit_model_gbc.predict(X_valid)\n",
    "y_proba_gbc = fit_model_gbc.predict_proba(X_valid)[:, 1] \n",
    "\n",
    "gbc_metrics_eval = get_final_metrics_df(\n",
    "    'gradient boosting classifier', \n",
    "    y_valid,   \n",
    "    y_pred_gbc,      \n",
    "    y_proba_gbc       \n",
    ")\n",
    "\n",
    "gbc_metrics_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dfb749",
   "metadata": {},
   "source": [
    "Based on these results, the model's accuracy appears to be quite good. However, other metrics like Recall, Precision, and F1-score show very poor performance in detecting the minority class (fraud). A score of 0.0 on these metrics indicates that the model is unable to recognize patterns to predict y = 1.\n",
    "\n",
    "The reasons:\n",
    "* The limited features available were not strong enough to find patterns that distinguish fraud.\n",
    "* Model Overfitting on Synthetic Data. Trained with SMOTE data, the model failed to generalize patterns from the synthetic data to the original validation data.\n",
    "* The model is overly biased towards the majority class due to not getting enough relevant information from the minority class, causing it to consistently predict y = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765b0fb",
   "metadata": {},
   "source": [
    "**The model is still overfitting** because it is only able to achieve a high score on this specific metric and is only good on data training. Meanwhile, a high recall is needed to show how well the model can reduce false negatives (detect all actual fraud cases), while a high precision is needed to show how accurate the model's fraud predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce92289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fold 0</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.982475</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.946565</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fold 1</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.990050</td>\n",
       "      <td>0.954887</td>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.940741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fold 2</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.974334</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.959677</td>\n",
       "      <td>0.926070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fold 3</td>\n",
       "      <td>0.954887</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>0.953846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fold 4</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.966250</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.917910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.936090</td>\n",
       "      <td>0.979637</td>\n",
       "      <td>0.927820</td>\n",
       "      <td>0.944148</td>\n",
       "      <td>0.935592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fold  Accuracy       AUC    Recall     Prec.        F1\n",
       "0  Fold 0  0.939850  0.982475  0.932331  0.946565  0.939394\n",
       "1  Fold 1  0.939850  0.990050  0.954887  0.927007  0.940741\n",
       "2  Fold 2  0.928571  0.974334  0.894737  0.959677  0.926070\n",
       "3  Fold 3  0.954887  0.985075  0.932331  0.976378  0.953846\n",
       "4  Fold 4  0.917293  0.966250  0.924812  0.911111  0.917910\n",
       "5    Mean  0.936090  0.979637  0.927820  0.944148  0.935592"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to fitting in mutlitple fold (xgb)\n",
    "single_model_cv_report(xgb_model, X_train_SMOTE, y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0392f244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Recall  Prec.   F1       AUC\n",
       "0  XGBoost Classifier  0.913333     0.0    0.0  0.0  0.383803"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the result on data that the model has never seen before\n",
    "# predict on set validation (X_valid)\n",
    "fit_model_xgb = xgb_model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "y_pred_xgb = fit_model_xgb.predict(X_valid)\n",
    "y_proba_xgb = fit_model_xgb.predict_proba(X_valid)[:, 1] \n",
    "\n",
    "xgb_metrics_eval = get_final_metrics_df(\n",
    "    'XGBoost Classifier', \n",
    "    y_valid,   \n",
    "    y_pred_xgb,      \n",
    "    y_proba_xgb       \n",
    ")\n",
    "\n",
    "xgb_metrics_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5eb048",
   "metadata": {},
   "source": [
    "The results will be more or less the same because both XGBoost and GradientBoost are ensemble tree techniques, with differences mainly in parameter naming and other implementation details. XGBoost is a Gradient Boosting implementation from the XGBoost library, while GradientBoost is the implementation from the scikit-learn library. The purpose of using both libraries is to find the best candidate for further tuning.\n",
    "\n",
    "**Therefore, the main problem remains the data, not the algorithm. Garbage in garbage out**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b8950",
   "metadata": {},
   "source": [
    "## Model lgb & dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49697b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fold 0</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.980044</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.937984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fold 1</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.988920</td>\n",
       "      <td>0.954887</td>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.940741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fold 2</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.964356</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.938931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fold 3</td>\n",
       "      <td>0.951128</td>\n",
       "      <td>0.987930</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.949416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fold 4</td>\n",
       "      <td>0.906015</td>\n",
       "      <td>0.964045</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.907063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.935338</td>\n",
       "      <td>0.977059</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.945885</td>\n",
       "      <td>0.934827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fold  Accuracy       AUC    Recall     Prec.        F1\n",
       "0  Fold 0  0.939850  0.980044  0.909774  0.968000  0.937984\n",
       "1  Fold 1  0.939850  0.988920  0.954887  0.927007  0.940741\n",
       "2  Fold 2  0.939850  0.964356  0.924812  0.953488  0.938931\n",
       "3  Fold 3  0.951128  0.987930  0.917293  0.983871  0.949416\n",
       "4  Fold 4  0.906015  0.964045  0.917293  0.897059  0.907063\n",
       "5    Mean  0.935338  0.977059  0.924812  0.945885  0.934827"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to fitting in mutlitple fold\n",
    "single_model_cv_report(lgb_model, X_train_SMOTE, y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe87f840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>light gradient boosting</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy  Recall  Prec.   F1       AUC\n",
       "0  light gradient boosting  0.886667     0.0    0.0  0.0  0.360035"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the result on data that the model has never seen before\n",
    "# predict on set validation (X_valid)\n",
    "fit_model_lgb = lgb_model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "y_pred_lgb = fit_model_lgb.predict(X_valid)\n",
    "y_proba_lgb = fit_model_lgb.predict_proba(X_valid)[:, 1] \n",
    "\n",
    "lgb_metrics_eval = get_final_metrics_df(\n",
    "    'light gradient boosting', \n",
    "    y_valid,   \n",
    "    y_pred_lgb,      \n",
    "    y_proba_lgb       \n",
    ")\n",
    "\n",
    "lgb_metrics_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037a7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fold 0</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.896296</td>\n",
       "      <td>0.902985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fold 1</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.921933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fold 2</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.914062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fold 3</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fold 4</td>\n",
       "      <td>0.898496</td>\n",
       "      <td>0.898496</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.898876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.912782</td>\n",
       "      <td>0.912782</td>\n",
       "      <td>0.912782</td>\n",
       "      <td>0.913442</td>\n",
       "      <td>0.912757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fold  Accuracy       AUC    Recall     Prec.        F1\n",
       "0  Fold 0  0.902256  0.902256  0.909774  0.896296  0.902985\n",
       "1  Fold 1  0.921053  0.921053  0.932331  0.911765  0.921933\n",
       "2  Fold 2  0.917293  0.917293  0.879699  0.951220  0.914062\n",
       "3  Fold 3  0.924812  0.924812  0.939850  0.912409  0.925926\n",
       "4  Fold 4  0.898496  0.898496  0.902256  0.895522  0.898876\n",
       "5    Mean  0.912782  0.912782  0.912782  0.913442  0.912757"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to fitting in mutlitple fold (decision tree)\n",
    "single_model_cv_report(dt_model, X_train_SMOTE, y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7eb386ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Recall  Prec.   F1       AUC\n",
       "0  decision tree      0.88     0.0    0.0  0.0  0.464789"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the result on data that the model has never seen before\n",
    "# predict on set validation (X_valid)\n",
    "fit_model_dt = dt_model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "y_pred_dt = fit_model_dt.predict(X_valid)\n",
    "y_proba_dt = fit_model_dt.predict_proba(X_valid)[:, 1] \n",
    "\n",
    "dt_metrics_eval = get_final_metrics_df(\n",
    "    'decision tree', \n",
    "    y_valid,   \n",
    "    y_pred_dt,      \n",
    "    y_proba_dt       \n",
    ")\n",
    "\n",
    "dt_metrics_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34544394",
   "metadata": {},
   "source": [
    "Based on these results, the Light Gradient Boosting and Decision Tree models yielded lower and not better accuracy scores compared to Gradient Boosting. **All models are overfitting**, and the next step is to attempt tuning. However, it is important to realize that tuning may not lead to significant changes, perhaps only a 1-5% improvement, because the main problem lies in the unrepresentative features that prevent the models from learning meaningful patterns. In some cases, a performance increase might not occur at all if the untuned model has already reached its \"best\" or peak performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d6e42",
   "metadata": {},
   "source": [
    "# Tuning\n",
    "\n",
    "The model that will be tuned is the best-performing one, which is `gradient boosting classifier` dari XGBoost.\n",
    "\n",
    "We'll using optuna to tune the model, ref:\n",
    "1. https://xgboosting.com/xgboost-hyperparameter-optimization-with-optuna/\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7668708",
   "metadata": {},
   "source": [
    "## First Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "361e03f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 19:47:37,447] A new study created in memory with name: no-name-aeefe774-b313-420b-be09-d269f3141ce3\n",
      "[I 2025-07-28 19:47:37,989] Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 450, 'learning_rate': 0.0027568874166751956, 'max_depth': 5, 'subsample': 0.6763517623718885, 'colsample_bytree': 0.9168052055412625, 'gamma': 0.7257158773350325, 'reg_alpha': 0.0007475545118584174, 'reg_lambda': 0.20415011123697693, 'min_child_weight': 9}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:38,229] Trial 1 finished with value: 0.0 and parameters: {'n_estimators': 296, 'learning_rate': 0.00017293031512919554, 'max_depth': 3, 'subsample': 0.8424959823610227, 'colsample_bytree': 0.8944697782628706, 'gamma': 0.38615355717810995, 'reg_alpha': 5.676774097553956, 'reg_lambda': 48.07213333773739, 'min_child_weight': 1}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:38,326] Trial 2 finished with value: 0.0 and parameters: {'n_estimators': 107, 'learning_rate': 0.00036814629725020955, 'max_depth': 5, 'subsample': 0.5767984774823212, 'colsample_bytree': 0.8272861621563011, 'gamma': 0.22765932736130057, 'reg_alpha': 30.366514715144586, 'reg_lambda': 1.2061323095494326e-05, 'min_child_weight': 7}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:38,504] Trial 3 finished with value: 0.0 and parameters: {'n_estimators': 454, 'learning_rate': 0.00013681554746540408, 'max_depth': 1, 'subsample': 0.7850659777368436, 'colsample_bytree': 0.5006568159918882, 'gamma': 0.056386295536393405, 'reg_alpha': 6.791515224119261, 'reg_lambda': 0.030141620066842796, 'min_child_weight': 5}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:38,726] Trial 4 finished with value: 0.0 and parameters: {'n_estimators': 270, 'learning_rate': 0.00036387102852094, 'max_depth': 8, 'subsample': 0.7718553438676343, 'colsample_bytree': 0.5416507038096834, 'gamma': 0.9057167717406117, 'reg_alpha': 1.6707880580167432e-07, 'reg_lambda': 2.198780872971513e-06, 'min_child_weight': 7}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:39,730] Trial 5 finished with value: 0.0 and parameters: {'n_estimators': 500, 'learning_rate': 0.026101896698728994, 'max_depth': 10, 'subsample': 0.7510193179680589, 'colsample_bytree': 0.9004649040099987, 'gamma': 0.8207232568908305, 'reg_alpha': 3.4286061376944065e-05, 'reg_lambda': 0.03840798465648098, 'min_child_weight': 2}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:40,320] Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 453, 'learning_rate': 0.00136735429167408, 'max_depth': 8, 'subsample': 0.7345494083430664, 'colsample_bytree': 0.6882504565096033, 'gamma': 0.6101353350417007, 'reg_alpha': 0.0013433150112964437, 'reg_lambda': 2.061638129802324e-06, 'min_child_weight': 3}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:41,045] Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 359, 'learning_rate': 0.024104400965597943, 'max_depth': 8, 'subsample': 0.5803602446634921, 'colsample_bytree': 0.8331297099652103, 'gamma': 0.1408997648598428, 'reg_alpha': 7.11945333014985e-07, 'reg_lambda': 39.32041619398582, 'min_child_weight': 1}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:41,266] Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 241, 'learning_rate': 0.07649454561061203, 'max_depth': 1, 'subsample': 0.6683968563111486, 'colsample_bytree': 0.5200493174830136, 'gamma': 0.8379140646257505, 'reg_alpha': 15.95278702713449, 'reg_lambda': 1.652014574675198e-05, 'min_child_weight': 5}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:41,791] Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 324, 'learning_rate': 0.00011886215866180926, 'max_depth': 8, 'subsample': 0.9327578306035187, 'colsample_bytree': 0.607774392871554, 'gamma': 0.32842797901229315, 'reg_alpha': 0.010135357142021933, 'reg_lambda': 0.00018425084923702728, 'min_child_weight': 4}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:41,980] Trial 10 finished with value: 0.0 and parameters: {'n_estimators': 130, 'learning_rate': 0.0033136697788605043, 'max_depth': 5, 'subsample': 0.5129797135050588, 'colsample_bytree': 0.9952834257209999, 'gamma': 0.6148101836327649, 'reg_alpha': 0.052732052497112145, 'reg_lambda': 1.237761345465681e-08, 'min_child_weight': 10}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:42,350] Trial 11 finished with value: 0.0 and parameters: {'n_estimators': 376, 'learning_rate': 0.0032178925256698223, 'max_depth': 3, 'subsample': 0.9083834669681312, 'colsample_bytree': 0.9810036564124094, 'gamma': 0.43000501349321285, 'reg_alpha': 0.17371487384919093, 'reg_lambda': 66.90905312449664, 'min_child_weight': 10}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:42,589] Trial 12 finished with value: 0.0 and parameters: {'n_estimators': 183, 'learning_rate': 0.0009601275508850544, 'max_depth': 3, 'subsample': 0.8480868034217678, 'colsample_bytree': 0.8974955976295169, 'gamma': 0.6670368415356758, 'reg_alpha': 6.72847964229208e-05, 'reg_lambda': 0.7770551825411002, 'min_child_weight': 8}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:42,969] Trial 13 finished with value: 0.0 and parameters: {'n_estimators': 404, 'learning_rate': 0.014839360104531773, 'max_depth': 3, 'subsample': 0.9876911485024069, 'colsample_bytree': 0.7602614516324551, 'gamma': 0.43571375562178477, 'reg_alpha': 3.384233042294343e-05, 'reg_lambda': 0.8925913974994134, 'min_child_weight': 8}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:43,111] Trial 14 finished with value: 0.0 and parameters: {'n_estimators': 53, 'learning_rate': 0.007629050733093345, 'max_depth': 6, 'subsample': 0.6651953076272009, 'colsample_bytree': 0.9175068408351715, 'gamma': 0.735022149817575, 'reg_alpha': 0.550060273716037, 'reg_lambda': 1.3278184383848612, 'min_child_weight': 1}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:43,424] Trial 15 finished with value: 0.0 and parameters: {'n_estimators': 309, 'learning_rate': 0.0005466944643405829, 'max_depth': 4, 'subsample': 0.84635844373812, 'colsample_bytree': 0.8059032432259957, 'gamma': 0.9853749353410463, 'reg_alpha': 0.0007376343632223901, 'reg_lambda': 0.011808517691000522, 'min_child_weight': 3}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:43,771] Trial 16 finished with value: 0.0 and parameters: {'n_estimators': 197, 'learning_rate': 0.001528173179438135, 'max_depth': 6, 'subsample': 0.6959389341403499, 'colsample_bytree': 0.6908523237502032, 'gamma': 0.4714384544218283, 'reg_alpha': 1.2512292744158187, 'reg_lambda': 6.046826824463594, 'min_child_weight': 9}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:44,038] Trial 17 finished with value: 0.0 and parameters: {'n_estimators': 430, 'learning_rate': 0.00673583428234138, 'max_depth': 2, 'subsample': 0.8513949675617297, 'colsample_bytree': 0.9246819239161613, 'gamma': 0.31141710026453995, 'reg_alpha': 2.864855827099051e-06, 'reg_lambda': 0.001831783248459846, 'min_child_weight': 6}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:44,504] Trial 18 finished with value: 0.0 and parameters: {'n_estimators': 497, 'learning_rate': 0.00023307037016645214, 'max_depth': 4, 'subsample': 0.6118725253728512, 'colsample_bytree': 0.8576584183248871, 'gamma': 0.541907713310323, 'reg_alpha': 0.006258395338578995, 'reg_lambda': 0.13292690961611667, 'min_child_weight': 4}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:44,821] Trial 19 finished with value: 0.0 and parameters: {'n_estimators': 320, 'learning_rate': 0.0982710576510882, 'max_depth': 7, 'subsample': 0.8094546244395385, 'colsample_bytree': 0.7665125398913591, 'gamma': 0.7619016851007888, 'reg_alpha': 0.0004354838369360932, 'reg_lambda': 8.048244169614836, 'min_child_weight': 6}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:45,133] Trial 20 finished with value: 0.0 and parameters: {'n_estimators': 227, 'learning_rate': 0.0007673003920800811, 'max_depth': 4, 'subsample': 0.7148348389054437, 'colsample_bytree': 0.9546150414920627, 'gamma': 0.3150974000053567, 'reg_alpha': 3.0888668153871945e-08, 'reg_lambda': 0.0014023333111076938, 'min_child_weight': 9}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:45,326] Trial 21 finished with value: 0.0 and parameters: {'n_estimators': 105, 'learning_rate': 0.0003201670665955769, 'max_depth': 5, 'subsample': 0.5928311705291641, 'colsample_bytree': 0.8591940177495426, 'gamma': 0.2596235440845545, 'reg_alpha': 39.70500418370517, 'reg_lambda': 0.00011851293914253718, 'min_child_weight': 7}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:45,507] Trial 22 finished with value: 0.0 and parameters: {'n_estimators': 153, 'learning_rate': 0.00024212446079897819, 'max_depth': 5, 'subsample': 0.6299780114038699, 'colsample_bytree': 0.8012112260449247, 'gamma': 0.18864065568888597, 'reg_alpha': 93.76934166991117, 'reg_lambda': 1.207105288961295e-08, 'min_child_weight': 8}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:45,628] Trial 23 finished with value: 0.0 and parameters: {'n_estimators': 61, 'learning_rate': 0.00011038392455929972, 'max_depth': 2, 'subsample': 0.5335486638093099, 'colsample_bytree': 0.8715102129977631, 'gamma': 0.38716159098766734, 'reg_alpha': 3.0880439829631694, 'reg_lambda': 2.346600381734518e-07, 'min_child_weight': 7}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:46,066] Trial 24 finished with value: 0.0 and parameters: {'n_estimators': 289, 'learning_rate': 0.0021076708918102323, 'max_depth': 6, 'subsample': 0.6531599185823229, 'colsample_bytree': 0.7154973664994477, 'gamma': 0.008818460247840998, 'reg_alpha': 0.07815309436657995, 'reg_lambda': 5.2386965001082104e-05, 'min_child_weight': 9}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:46,389] Trial 25 finished with value: 0.0 and parameters: {'n_estimators': 372, 'learning_rate': 0.0005396765628136234, 'max_depth': 4, 'subsample': 0.5703329274216264, 'colsample_bytree': 0.9399358678315984, 'gamma': 0.19420324341657605, 'reg_alpha': 0.016314990271077127, 'reg_lambda': 0.18585661258379851, 'min_child_weight': 6}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:46,561] Trial 26 finished with value: 0.0 and parameters: {'n_estimators': 99, 'learning_rate': 0.00019763812637818207, 'max_depth': 7, 'subsample': 0.9145310544237966, 'colsample_bytree': 0.8183414578149284, 'gamma': 0.5462330448887809, 'reg_alpha': 0.38114493798735233, 'reg_lambda': 0.005736369928138833, 'min_child_weight': 7}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:46,778] Trial 27 finished with value: 0.0 and parameters: {'n_estimators': 246, 'learning_rate': 0.0054688917690187576, 'max_depth': 2, 'subsample': 0.5489682047379694, 'colsample_bytree': 0.9619061848807017, 'gamma': 0.2538964871429423, 'reg_alpha': 7.384256597206635, 'reg_lambda': 5.162419385022092, 'min_child_weight': 8}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:46,938] Trial 28 finished with value: 0.0 and parameters: {'n_estimators': 190, 'learning_rate': 0.0005187766927055454, 'max_depth': 5, 'subsample': 0.6981415775800139, 'colsample_bytree': 0.8876902701537941, 'gamma': 0.10135249504874666, 'reg_alpha': 89.48925664856284, 'reg_lambda': 4.7881489670647915e-06, 'min_child_weight': 10}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 19:47:47,193] Trial 29 finished with value: 0.05 and parameters: {'n_estimators': 409, 'learning_rate': 0.00017056688653990275, 'max_depth': 1, 'subsample': 0.7959500610308742, 'colsample_bytree': 0.8390957615019836, 'gamma': 0.3728150161437189, 'reg_alpha': 2.9930242625937518, 'reg_lambda': 0.07373738212922361, 'min_child_weight': 5}. Best is trial 29 with value: 0.05.\n",
      "[I 2025-07-28 19:47:47,458] Trial 30 finished with value: 0.05 and parameters: {'n_estimators': 406, 'learning_rate': 0.0001768359168220996, 'max_depth': 1, 'subsample': 0.772202188654726, 'colsample_bytree': 0.8414859318104947, 'gamma': 0.5172922881751292, 'reg_alpha': 1.902380159001521, 'reg_lambda': 0.19099950974644875, 'min_child_weight': 2}. Best is trial 29 with value: 0.05.\n",
      "[I 2025-07-28 19:47:47,693] Trial 31 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 419, 'learning_rate': 0.0001905922401758238, 'max_depth': 1, 'subsample': 0.8085294361775452, 'colsample_bytree': 0.842048275045803, 'gamma': 0.5166454705130621, 'reg_alpha': 1.3407220443750072, 'reg_lambda': 0.14602298892752497, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:47,943] Trial 32 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 415, 'learning_rate': 0.00018213104876859627, 'max_depth': 1, 'subsample': 0.8212275476610474, 'colsample_bytree': 0.7791865372184958, 'gamma': 0.5293029811592178, 'reg_alpha': 0.9756586732612006, 'reg_lambda': 0.29860539891160454, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:48,234] Trial 33 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 421, 'learning_rate': 0.00017588798155799486, 'max_depth': 1, 'subsample': 0.8769590001314472, 'colsample_bytree': 0.7862686764317223, 'gamma': 0.5188158190899066, 'reg_alpha': 1.629499843439846, 'reg_lambda': 0.0550033180781327, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:48,498] Trial 34 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 428, 'learning_rate': 0.0001057181480244539, 'max_depth': 1, 'subsample': 0.8104332263778711, 'colsample_bytree': 0.7841293918055725, 'gamma': 0.5876662851686564, 'reg_alpha': 0.6263074874036403, 'reg_lambda': 0.029770222476511263, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:48,821] Trial 35 finished with value: 0.0 and parameters: {'n_estimators': 476, 'learning_rate': 0.0001108326432340534, 'max_depth': 2, 'subsample': 0.8240604045003914, 'colsample_bytree': 0.7272290696850735, 'gamma': 0.6108328181617418, 'reg_alpha': 0.4858125621933567, 'reg_lambda': 0.0064272560108903105, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:49,044] Trial 36 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 351, 'learning_rate': 0.0003080571065381917, 'max_depth': 1, 'subsample': 0.8830545573803514, 'colsample_bytree': 0.7847453859228525, 'gamma': 0.6452429281088209, 'reg_alpha': 0.024972754943966856, 'reg_lambda': 0.02460889032250731, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:49,496] Trial 37 finished with value: 0.0 and parameters: {'n_estimators': 438, 'learning_rate': 0.0003653114583003462, 'max_depth': 2, 'subsample': 0.8749935064339116, 'colsample_bytree': 0.6497537903781794, 'gamma': 0.6877357116696321, 'reg_alpha': 0.09603455330423584, 'reg_lambda': 0.8376299667775562, 'min_child_weight': 1}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:49,777] Trial 38 finished with value: 0.0 and parameters: {'n_estimators': 475, 'learning_rate': 0.0001541900852596276, 'max_depth': 1, 'subsample': 0.9554647211359372, 'colsample_bytree': 0.7470047062898963, 'gamma': 0.5681172662483933, 'reg_alpha': 12.730129642182504, 'reg_lambda': 0.0008499647379061613, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:50,063] Trial 39 finished with value: 0.0 and parameters: {'n_estimators': 420, 'learning_rate': 0.0007677228505657367, 'max_depth': 2, 'subsample': 0.7569095826382854, 'colsample_bytree': 0.786472423166114, 'gamma': 0.48246130287775135, 'reg_alpha': 0.0041844193715737015, 'reg_lambda': 0.025955393722199745, 'min_child_weight': 4}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:50,311] Trial 40 finished with value: 0.05 and parameters: {'n_estimators': 387, 'learning_rate': 0.00023709522832236703, 'max_depth': 1, 'subsample': 0.8166856922613982, 'colsample_bytree': 0.6456910891497001, 'gamma': 0.5854607442403399, 'reg_alpha': 0.8430871622548096, 'reg_lambda': 0.3437891678935065, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:50,585] Trial 41 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 362, 'learning_rate': 0.00030418884827139003, 'max_depth': 1, 'subsample': 0.8834575132979712, 'colsample_bytree': 0.7782003275074327, 'gamma': 0.6808833621083702, 'reg_alpha': 0.026056065483960843, 'reg_lambda': 0.017031331966164954, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:50,886] Trial 42 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 336, 'learning_rate': 0.000107840757338627, 'max_depth': 1, 'subsample': 0.8746295236566852, 'colsample_bytree': 0.733130738976207, 'gamma': 0.6342409479692073, 'reg_alpha': 0.16560535990031205, 'reg_lambda': 0.03764886788134495, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:51,655] Trial 43 finished with value: 0.0 and parameters: {'n_estimators': 457, 'learning_rate': 0.0001556881386606332, 'max_depth': 10, 'subsample': 0.7886260072228275, 'colsample_bytree': 0.7925429438296141, 'gamma': 0.7714998530751936, 'reg_alpha': 0.035351664357875144, 'reg_lambda': 0.003480772441133866, 'min_child_weight': 1}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:51,910] Trial 44 finished with value: 0.0 and parameters: {'n_estimators': 388, 'learning_rate': 0.0004360455540636671, 'max_depth': 2, 'subsample': 0.9025316261605287, 'colsample_bytree': 0.6999316113366114, 'gamma': 0.4897517745479186, 'reg_alpha': 0.20663064659168437, 'reg_lambda': 0.0796849618427905, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:52,117] Trial 45 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 347, 'learning_rate': 0.0002594278338970435, 'max_depth': 1, 'subsample': 0.9377132527349312, 'colsample_bytree': 0.8199447261038507, 'gamma': 0.4307322421086173, 'reg_alpha': 3.9789050495155913, 'reg_lambda': 2.443616031183306, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:52,458] Trial 46 finished with value: 0.0 and parameters: {'n_estimators': 449, 'learning_rate': 0.00014514322629164637, 'max_depth': 3, 'subsample': 0.8313081749375912, 'colsample_bytree': 0.7524160653005699, 'gamma': 0.8304436114440589, 'reg_alpha': 0.0019895792176105563, 'reg_lambda': 0.0003928632000417667, 'min_child_weight': 1}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:52,758] Trial 47 finished with value: 0.0 and parameters: {'n_estimators': 394, 'learning_rate': 0.0003942829797694158, 'max_depth': 3, 'subsample': 0.7381331378325647, 'colsample_bytree': 0.7845437441299348, 'gamma': 0.6441193895942541, 'reg_alpha': 23.453902641178743, 'reg_lambda': 0.48887779249469926, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:53,069] Trial 48 finished with value: 0.05 and parameters: {'n_estimators': 423, 'learning_rate': 0.00010103964918536973, 'max_depth': 1, 'subsample': 0.8613100206979262, 'colsample_bytree': 0.6687049861668236, 'gamma': 0.5216814081664949, 'reg_alpha': 0.7208286029182219, 'reg_lambda': 0.0632105456901724, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:53,645] Trial 49 finished with value: 0.0 and parameters: {'n_estimators': 472, 'learning_rate': 0.0010991897359798875, 'max_depth': 9, 'subsample': 0.9697801340341261, 'colsample_bytree': 0.8214480449377516, 'gamma': 0.5772909913205243, 'reg_alpha': 7.933243325338227, 'reg_lambda': 0.012287415386232976, 'min_child_weight': 4}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:53,897] Trial 50 finished with value: 0.0 and parameters: {'n_estimators': 354, 'learning_rate': 0.00020806207453276512, 'max_depth': 2, 'subsample': 0.8942374239330078, 'colsample_bytree': 0.7650778583120788, 'gamma': 0.39111528199592893, 'reg_alpha': 0.22927961822891196, 'reg_lambda': 2.8428283083876256, 'min_child_weight': 1}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:54,116] Trial 51 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 374, 'learning_rate': 0.00028653244162901384, 'max_depth': 1, 'subsample': 0.881835059829048, 'colsample_bytree': 0.7787636625139143, 'gamma': 0.6871664155704722, 'reg_alpha': 0.01210535109690255, 'reg_lambda': 0.02071810352684292, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:54,355] Trial 52 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 362, 'learning_rate': 0.0003117921470760052, 'max_depth': 1, 'subsample': 0.9269919499995442, 'colsample_bytree': 0.740823840183545, 'gamma': 0.7092623924799188, 'reg_alpha': 0.03137381305489906, 'reg_lambda': 0.012736798364538254, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:54,649] Trial 53 finished with value: 0.0 and parameters: {'n_estimators': 439, 'learning_rate': 0.00013506562554329164, 'max_depth': 2, 'subsample': 0.8066610526479979, 'colsample_bytree': 0.8064207807924846, 'gamma': 0.6474339068982906, 'reg_alpha': 0.0002393117186297439, 'reg_lambda': 14.2555013734238, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:54,893] Trial 54 finished with value: 0.05 and parameters: {'n_estimators': 418, 'learning_rate': 0.0006768502326865729, 'max_depth': 1, 'subsample': 0.8375325433276966, 'colsample_bytree': 0.8528329671970947, 'gamma': 0.8746088765738276, 'reg_alpha': 1.2223430028619238, 'reg_lambda': 0.25779453134404795, 'min_child_weight': 4}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:55,102] Trial 55 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 330, 'learning_rate': 0.00019102750728559412, 'max_depth': 1, 'subsample': 0.7734806349293856, 'colsample_bytree': 0.7696334461141745, 'gamma': 0.45849315696562515, 'reg_alpha': 0.027237649267950893, 'reg_lambda': 0.004098120617063633, 'min_child_weight': 1}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:55,438] Trial 56 finished with value: 0.0 and parameters: {'n_estimators': 302, 'learning_rate': 0.03256092207436335, 'max_depth': 2, 'subsample': 0.8503418384843131, 'colsample_bytree': 0.8828422702660085, 'gamma': 0.7677334099569505, 'reg_alpha': 0.003915932240122905, 'reg_lambda': 0.09044111980871909, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:55,791] Trial 57 finished with value: 0.0 and parameters: {'n_estimators': 398, 'learning_rate': 0.00045138535586282055, 'max_depth': 3, 'subsample': 0.8947800859969869, 'colsample_bytree': 0.5684996846765571, 'gamma': 0.7332791051704793, 'reg_alpha': 0.12504369329959636, 'reg_lambda': 0.03552303199246116, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:56,053] Trial 58 finished with value: 0.0 and parameters: {'n_estimators': 272, 'learning_rate': 0.00030133392898597423, 'max_depth': 3, 'subsample': 0.8698651565588301, 'colsample_bytree': 0.7075001153123917, 'gamma': 0.5979430007350891, 'reg_alpha': 0.06957516565197355, 'reg_lambda': 0.0007165153206207197, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:56,329] Trial 59 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 459, 'learning_rate': 0.00021621756849602718, 'max_depth': 1, 'subsample': 0.7582661453995009, 'colsample_bytree': 0.8013352968850156, 'gamma': 0.5224374069703628, 'reg_alpha': 0.3442286987225419, 'reg_lambda': 0.002310267638095157, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:56,586] Trial 60 finished with value: 0.0 and parameters: {'n_estimators': 370, 'learning_rate': 0.00013383392213733823, 'max_depth': 2, 'subsample': 0.8067440653035904, 'colsample_bytree': 0.8365521749831203, 'gamma': 0.5636857826040188, 'reg_alpha': 1.726336231836849, 'reg_lambda': 24.547215553305925, 'min_child_weight': 4}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:56,815] Trial 61 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 346, 'learning_rate': 0.00010025481154009326, 'max_depth': 1, 'subsample': 0.8866433962038395, 'colsample_bytree': 0.722330752379201, 'gamma': 0.6319001343891667, 'reg_alpha': 0.3136236516679592, 'reg_lambda': 0.049390059560648084, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:57,020] Trial 62 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 336, 'learning_rate': 0.0001294290899050078, 'max_depth': 1, 'subsample': 0.8561265134566374, 'colsample_bytree': 0.7468389974927404, 'gamma': 0.6667198425758869, 'reg_alpha': 0.12709462430066593, 'reg_lambda': 0.009590177853872082, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:57,220] Trial 63 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 312, 'learning_rate': 0.00016612175106792417, 'max_depth': 1, 'subsample': 0.9177839031762066, 'colsample_bytree': 0.7350070607994761, 'gamma': 0.6135336149487927, 'reg_alpha': 0.8369299720311849, 'reg_lambda': 0.44126038441586435, 'min_child_weight': 1}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:57,476] Trial 64 finished with value: 0.0 and parameters: {'n_estimators': 385, 'learning_rate': 0.00026262620566841884, 'max_depth': 2, 'subsample': 0.8310537428676945, 'colsample_bytree': 0.7678478197594288, 'gamma': 0.5542591559857675, 'reg_alpha': 0.01538706639128606, 'reg_lambda': 0.024187805388488255, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:57,780] Trial 65 finished with value: 0.05 and parameters: {'n_estimators': 434, 'learning_rate': 0.00012317101750695334, 'max_depth': 1, 'subsample': 0.868951359326508, 'colsample_bytree': 0.6834516515749844, 'gamma': 0.4487578987115496, 'reg_alpha': 0.052505261869708636, 'reg_lambda': 1.7394468617359649, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:57,998] Trial 66 finished with value: 0.0 and parameters: {'n_estimators': 292, 'learning_rate': 0.00019770549673434675, 'max_depth': 2, 'subsample': 0.9449890434373514, 'colsample_bytree': 0.8160572366736717, 'gamma': 0.8018377392089507, 'reg_alpha': 2.403372294617821, 'reg_lambda': 0.11560058758647009, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:58,273] Trial 67 finished with value: 0.027777777777777776 and parameters: {'n_estimators': 495, 'learning_rate': 0.0006359350278659087, 'max_depth': 1, 'subsample': 0.7932122231379326, 'colsample_bytree': 0.7789337490464282, 'gamma': 0.6960022555653781, 'reg_alpha': 5.352792047364114, 'reg_lambda': 0.17892760755626444, 'min_child_weight': 1}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:58,549] Trial 68 finished with value: 0.0 and parameters: {'n_estimators': 413, 'learning_rate': 0.0016064778350503397, 'max_depth': 2, 'subsample': 0.8447014058780655, 'colsample_bytree': 0.8651233975037136, 'gamma': 0.4960620697311564, 'reg_alpha': 0.008330738300016917, 'reg_lambda': 0.7712259844003562, 'min_child_weight': 5}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:58,719] Trial 69 finished with value: 0.030303030303030304 and parameters: {'n_estimators': 252, 'learning_rate': 0.00033183956363306725, 'max_depth': 1, 'subsample': 0.9065791200454728, 'colsample_bytree': 0.9070008831305795, 'gamma': 0.537735233149665, 'reg_alpha': 40.98161291325353, 'reg_lambda': 0.03949228358673257, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:58,933] Trial 70 finished with value: 0.0 and parameters: {'n_estimators': 336, 'learning_rate': 0.014142916069252913, 'max_depth': 1, 'subsample': 0.8214535651877517, 'colsample_bytree': 0.7994217408063905, 'gamma': 0.3993047604046516, 'reg_alpha': 15.343589690530308, 'reg_lambda': 0.020916756777990708, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:59,145] Trial 71 finished with value: 0.044444444444444446 and parameters: {'n_estimators': 351, 'learning_rate': 0.00025234517515405896, 'max_depth': 1, 'subsample': 0.9366371844474431, 'colsample_bytree': 0.8215406003218724, 'gamma': 0.40777922513089637, 'reg_alpha': 3.4243935220403103, 'reg_lambda': 4.844699822539408, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:59,409] Trial 72 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 362, 'learning_rate': 0.00016493432521330698, 'max_depth': 1, 'subsample': 0.9927194932197252, 'colsample_bytree': 0.7571869863878913, 'gamma': 0.351932656824144, 'reg_alpha': 4.757182160739964, 'reg_lambda': 1.4779729396218857, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:59,666] Trial 73 finished with value: 0.0 and parameters: {'n_estimators': 316, 'learning_rate': 0.00024669334926945155, 'max_depth': 2, 'subsample': 0.9230630610619198, 'colsample_bytree': 0.8343179048706754, 'gamma': 0.4232392899590531, 'reg_alpha': 0.44191992998605467, 'reg_lambda': 94.84841394386173, 'min_child_weight': 4}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:47:59,923] Trial 74 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 402, 'learning_rate': 0.0004071930097076592, 'max_depth': 1, 'subsample': 0.9616410439476855, 'colsample_bytree': 0.8464133378062674, 'gamma': 0.6594489407917625, 'reg_alpha': 0.9949859972072641, 'reg_lambda': 0.29940233303739805, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:00,299] Trial 75 finished with value: 0.0 and parameters: {'n_estimators': 380, 'learning_rate': 0.00012900798240723197, 'max_depth': 2, 'subsample': 0.8774601156202374, 'colsample_bytree': 0.8112244068073479, 'gamma': 0.4659243973227333, 'reg_alpha': 0.1736238804452505, 'reg_lambda': 0.006776030012655005, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:00,538] Trial 76 finished with value: 0.05 and parameters: {'n_estimators': 341, 'learning_rate': 0.00018803498112643035, 'max_depth': 1, 'subsample': 0.8609976781242749, 'colsample_bytree': 0.7806348396698812, 'gamma': 0.6216796733368738, 'reg_alpha': 1.7768244830041222, 'reg_lambda': 2.621783715043401, 'min_child_weight': 1}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:00,827] Trial 77 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 283, 'learning_rate': 0.00010009799012195586, 'max_depth': 1, 'subsample': 0.9458065812379809, 'colsample_bytree': 0.7950890373219422, 'gamma': 0.5867113160597058, 'reg_alpha': 0.4920756121690558, 'reg_lambda': 0.1321543719474112, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:01,150] Trial 78 finished with value: 0.0 and parameters: {'n_estimators': 448, 'learning_rate': 0.00015673546233283513, 'max_depth': 2, 'subsample': 0.9768183877610301, 'colsample_bytree': 0.7358150522369628, 'gamma': 0.49853088277949803, 'reg_alpha': 2.0185201045017513e-06, 'reg_lambda': 0.7556352161749254, 'min_child_weight': 4}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:01,574] Trial 79 finished with value: 0.0 and parameters: {'n_estimators': 429, 'learning_rate': 0.0005106814156708256, 'max_depth': 3, 'subsample': 0.8919358414410907, 'colsample_bytree': 0.826339585408953, 'gamma': 0.7214662134570041, 'reg_alpha': 7.986048009272822, 'reg_lambda': 0.0026060347596695193, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:02,100] Trial 80 finished with value: 0.0 and parameters: {'n_estimators': 323, 'learning_rate': 0.0003615418323899724, 'max_depth': 7, 'subsample': 0.7815304369280288, 'colsample_bytree': 0.8760053728971616, 'gamma': 0.5312488629420153, 'reg_alpha': 0.05675742576544731, 'reg_lambda': 0.06053712639434187, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:02,329] Trial 81 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 371, 'learning_rate': 0.0002866073187417254, 'max_depth': 1, 'subsample': 0.8825922520745256, 'colsample_bytree': 0.7829604311611916, 'gamma': 0.6838957460799684, 'reg_alpha': 0.013636335928305196, 'reg_lambda': 0.014837759477186133, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:02,685] Trial 82 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 397, 'learning_rate': 0.00028379842674694945, 'max_depth': 1, 'subsample': 0.8376765869538383, 'colsample_bytree': 0.7705969389157071, 'gamma': 0.7488157594725513, 'reg_alpha': 0.0014269092421122806, 'reg_lambda': 0.023727231574079737, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:02,904] Trial 83 finished with value: 0.0 and parameters: {'n_estimators': 377, 'learning_rate': 0.003857925984671112, 'max_depth': 1, 'subsample': 0.9087903300408242, 'colsample_bytree': 0.755169358959794, 'gamma': 0.6719787933683895, 'reg_alpha': 0.025626293106429065, 'reg_lambda': 0.005089766114919813, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:03,139] Trial 84 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 412, 'learning_rate': 0.00022255850002929502, 'max_depth': 1, 'subsample': 0.860985512978158, 'colsample_bytree': 0.7161894798640935, 'gamma': 0.63656538928421, 'reg_alpha': 0.0031289413125481615, 'reg_lambda': 0.045381222691667805, 'min_child_weight': 1}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:03,428] Trial 85 finished with value: 0.0 and parameters: {'n_estimators': 364, 'learning_rate': 0.00011921160659338242, 'max_depth': 2, 'subsample': 0.8021111831333093, 'colsample_bytree': 0.7939703278341278, 'gamma': 0.5674274758818368, 'reg_alpha': 0.0006232940889511953, 'reg_lambda': 0.46533520765155445, 'min_child_weight': 4}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:03,664] Trial 86 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 392, 'learning_rate': 0.00018251599319310386, 'max_depth': 1, 'subsample': 0.8185418927747826, 'colsample_bytree': 0.8071934929346802, 'gamma': 0.708052540773028, 'reg_alpha': 0.00653743217610331, 'reg_lambda': 0.10312582268844364, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:03,950] Trial 87 finished with value: 0.0 and parameters: {'n_estimators': 424, 'learning_rate': 0.0009305991558823431, 'max_depth': 2, 'subsample': 0.7267228185242336, 'colsample_bytree': 0.7755658693426462, 'gamma': 0.6012491012235451, 'reg_alpha': 0.21850286619020462, 'reg_lambda': 0.0013299098666740463, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:04,224] Trial 88 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 353, 'learning_rate': 0.00014438311520593717, 'max_depth': 1, 'subsample': 0.8999021634416163, 'colsample_bytree': 0.7584033216090469, 'gamma': 0.43479388114940243, 'reg_alpha': 0.10492898849599469, 'reg_lambda': 0.23710888640367744, 'min_child_weight': 5}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:04,455] Trial 89 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 405, 'learning_rate': 0.00046614224970217057, 'max_depth': 1, 'subsample': 0.8780374028606458, 'colsample_bytree': 0.7287676292879898, 'gamma': 0.7864478557202484, 'reg_alpha': 1.188482290622683, 'reg_lambda': 2.3671914985770083e-07, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:04,692] Trial 90 finished with value: 0.0 and parameters: {'n_estimators': 303, 'learning_rate': 0.00035518785790148274, 'max_depth': 2, 'subsample': 0.9325357185299318, 'colsample_bytree': 0.8510539893194495, 'gamma': 0.5169137269380414, 'reg_alpha': 0.6845001726869557, 'reg_lambda': 0.007396211908316174, 'min_child_weight': 4}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:04,973] Trial 91 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 360, 'learning_rate': 0.00029522279482308017, 'max_depth': 1, 'subsample': 0.9268853446758487, 'colsample_bytree': 0.736622371414674, 'gamma': 0.7063404355345054, 'reg_alpha': 0.03573102116846019, 'reg_lambda': 0.012244518464945406, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:05,202] Trial 92 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 376, 'learning_rate': 0.00021517201584927764, 'max_depth': 1, 'subsample': 0.9183089632168819, 'colsample_bytree': 0.7444188454658436, 'gamma': 0.6509325363095084, 'reg_alpha': 0.01676217366550067, 'reg_lambda': 0.02244712810418829, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:05,410] Trial 93 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 332, 'learning_rate': 0.0005952642473605795, 'max_depth': 1, 'subsample': 0.9491081266679195, 'colsample_bytree': 0.7885320627346856, 'gamma': 0.740574311960515, 'reg_alpha': 0.051836556033186466, 'reg_lambda': 0.018045176490304227, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:05,867] Trial 94 finished with value: 0.0 and parameters: {'n_estimators': 345, 'learning_rate': 0.00031411800483469455, 'max_depth': 9, 'subsample': 0.8877637632750732, 'colsample_bytree': 0.6999295122813546, 'gamma': 0.6154105427408337, 'reg_alpha': 0.02691556730138311, 'reg_lambda': 0.000444198117810537, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:06,151] Trial 95 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 469, 'learning_rate': 0.00024257802006138899, 'max_depth': 1, 'subsample': 0.8498697497564959, 'colsample_bytree': 0.8259422377860723, 'gamma': 0.866360059255454, 'reg_alpha': 0.29339909127224634, 'reg_lambda': 0.04040704375906559, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:06,450] Trial 96 finished with value: 0.0 and parameters: {'n_estimators': 444, 'learning_rate': 0.00011148171365273531, 'max_depth': 2, 'subsample': 0.8704151395846624, 'colsample_bytree': 0.7433919560453616, 'gamma': 0.479845446811208, 'reg_alpha': 0.12819225749114782, 'reg_lambda': 0.08099417773978676, 'min_child_weight': 1}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:06,685] Trial 97 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 386, 'learning_rate': 0.00014343408080708792, 'max_depth': 1, 'subsample': 0.8308801506195937, 'colsample_bytree': 0.7655359700866141, 'gamma': 0.5517641638043185, 'reg_alpha': 1.4940632455461927e-07, 'reg_lambda': 0.00981105793078694, 'min_child_weight': 3}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:06,928] Trial 98 finished with value: 0.09803921568627451 and parameters: {'n_estimators': 366, 'learning_rate': 0.00018079457175663175, 'max_depth': 1, 'subsample': 0.9053266770204863, 'colsample_bytree': 0.8090989653413535, 'gamma': 0.6803352987183524, 'reg_alpha': 3.6780251267006556, 'reg_lambda': 0.16581122557718672, 'min_child_weight': 2}. Best is trial 31 with value: 0.09803921568627451.\n",
      "[I 2025-07-28 19:48:07,318] Trial 99 finished with value: 0.0 and parameters: {'n_estimators': 414, 'learning_rate': 0.00027030013266558404, 'max_depth': 2, 'subsample': 0.9741132589274712, 'colsample_bytree': 0.7729265336409756, 'gamma': 0.5863526681727003, 'reg_alpha': 10.223141541395313, 'reg_lambda': 0.002891790730463802, 'min_child_weight': 4}. Best is trial 31 with value: 0.09803921568627451.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test F1-score: 0.0980\n",
      "Best parameters: {'n_estimators': 419, 'learning_rate': 0.0001905922401758238, 'max_depth': 1, 'subsample': 0.8085294361775452, 'colsample_bytree': 0.842048275045803, 'gamma': 0.5166454705130621, 'reg_alpha': 1.3407220443750072, 'reg_lambda': 0.14602298892752497, 'min_child_weight': 2}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # define hyperparameter\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 100.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 100.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'random_state': 42,\n",
    "    }\n",
    "    \n",
    "    # create and train XGBoost Classifier\n",
    "    xgb_classifier = xgb.XGBClassifier(**params)\n",
    "    xgb_classifier.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "    \n",
    "    # Evaluate model on validation set\n",
    "    y_pred = xgb_classifier.predict(X_valid)\n",
    "    f1 = f1_score(y_valid, y_pred, zero_division=0)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "# Optimize parameters using Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "best_params = study.best_params\n",
    "best_model = xgb.XGBClassifier(**best_params)\n",
    "best_model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "# Evaluate best model on test set\n",
    "y_pred_test = best_model.predict(X_valid)\n",
    "test_f1_score = f1_score(y_valid, y_pred_test, zero_division=0)\n",
    "\n",
    "print(f\"Best test F1-score: {test_f1_score:.4f}\")\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bce3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of result first tuned\n",
    "results = {\n",
    "\"best_f1_score\": test_f1_score,\n",
    "\"best_parameters\": best_params\n",
    "}\n",
    "\n",
    "# name file\n",
    "output_filepath = 'first_tuned_params.json'\n",
    "\n",
    "# dump into file\n",
    "with open(output_filepath, 'w') as json_file:\n",
    "    json.dump(results, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b06c463",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22b350f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Tuned</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.10989</td>\n",
       "      <td>0.531469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy    Recall     Prec.       F1       AUC\n",
       "0  XGBoost Tuned      0.46  0.714286  0.059524  0.10989  0.531469"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit with best_model\n",
    "model_xgb_tuned = best_model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "# evaluation on set testing\n",
    "y_pred_xgb_tuned = model_xgb_tuned.predict(X_test)\n",
    "y_proba_xgb_tuned = model_xgb_tuned.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xgb_tuned_metrics_eval = get_final_metrics_df(\n",
    "    'XGBoost Tuned',\n",
    "    y_test,\n",
    "    y_pred_xgb_tuned,\n",
    "    y_proba_xgb_tuned\n",
    ")\n",
    "\n",
    "xgb_tuned_metrics_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639e495",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4c8dd6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
